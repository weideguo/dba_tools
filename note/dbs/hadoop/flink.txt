实时计算


1、Program Code：我们编写的 Flink 应用程序代码

2、Job Client：Job Client 不是 Flink 程序执行的内部部分，但它是任务执行的起点。Job Client 负责接受用户的程序代码，然后创建数据流，将数据流提交给 Job Manager 以便进一步执行。执行完成后，Job Client 将结果返回给用户

##在hadoop中以下使用yarn?
3、Job Manager：主进程（也称为作业管理器）协调和管理程序的执行。它的主要职责包括安排任务，管理 checkpoint ，故障恢复等。机器集群中至少要有一个 master，master 负责调度 task，协调 checkpoints 和容灾，高可用设置的话可以有多个 master，但要保证一个是 leader, 其他是 standby; Job Manager 包含 Actor system、Scheduler、Check pointing 三个重要的组件

4、Task Manager：从 Job Manager 处接收需要部署的 Task。Task Manager 是在 JVM 中的一个或多个线程中执行任务的工作节点。任务执行的并行性由每个 Task Manager 上可用的任务槽（Slot 个数）决定。每个任务代表分配给任务槽的一组资源。例如，如果 Task Manager 有四个插槽，那么它将为每个插槽分配 25％ 的内存。可以在任务槽中运行一个或多个线程。同一插槽中的线程共享相同的 JVM。



##Flink 应用程序结构

Source：数据输入
Transformation：数据转换的各种操作
Sink：数据输出



##提交作业模式

yarn seesion(Start a long-running Flink cluster on YARN)
这种方式需要先启动集群，然后在提交作业，接着会向yarn申请一块空间后，资源永远保持不变。如果资源满了，下一个作业就无法提交，只能等到yarn中的其中一个作业执行完成后，释放了资源，那下一个作业才会正常提交。

#yarn seesion客户端模式 可以有多个yarn session，一个yarn session对应一个JobManager
bin/yarn-session.sh -n 2 -jm 1024 -tm 4096 -s 6           
#-d指定yarn seesion分离模式 只有一个个yarn session，客户端在启动Flink Yarn Session后，就不再属于Yarn Cluster的一部分

#查看<Application ID> 
yarn application -list
#停止Flink Yarn Application
yarn application -kill <Application ID> 


Flink run
直接在YARN上提交运行Flink作业(Run a Flink job on YARN)，这种方式的好处是一个任务会对应一个job，即每提交一个作业会根据自身的情况，向yarn申请资源，直到作业执行完成，并不会影响下一个作业的正常运行，除非是yarn上面没有任何资源。



#提交作业

#使用样例jar

#yarn seesion 模式运行 

bin/flink run ./examples/batch/WordCount.jar  --input hdfs://10.10.149.5:8020/tmp/flink_test.txt  --output hdfs://10.10.149.5:8020/tmp/flink_test.result.txt

hadoop fs -cat /tmp/flink_test.result.txt


#Flink run 模式运行

bin/flink run -m yarn-cluster -d -yn 2 -yjm 2048 -ytm 5120 ./examples/batch/WordCount.jar  --input hdfs://10.10.149.5:8020/tmp/flink_test.txt  --output hdfs://10.10.149.5:8020/tmp/flink_test.result.txt




#pyfink
bin/flink run -py examples/python/table/batch/word_count.py 


bin/pyflink-shell.sh remote 127.0.0.1 8081 examples/python/table/batch/word_count.py           #YarnSessionClusterEntrypoint 监听的ip以及端口
bin/pyflink-shell.sh local examples/python/table/batch/word_count.py                           #启动一个mini Cluste



#处理流程
消息队列/日志文件 -> flink -> 存储 -> 数据展示













