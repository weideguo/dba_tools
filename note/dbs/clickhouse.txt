列式数据库 用于olap

类sql语句


单节点
clickhouse-client package contains clickhouse-client application, interactive ClickHouse console client.
clickhouse-common package contains a ClickHouse executable file.
clickhouse-server package contains configuration files to run ClickHouse as a server.


集群
Install ClickHouse server on all machines of the cluster
Set up cluster configs in configuration files
Create local tables on each instance
Create a Distributed table

集群使用zookeeper




#启动
clickhouse-server --config-file=/etc/clickhouse-server/config.xml

#监听端口
http_port                    #
tcp_port                     #原生的端口 如clickhouse-client连接使用
postgresql_port              #兼容postgresql协议的端口
mysql_port                   #兼容mysql协议的端口
interserver_http_port        #副本之间的通信，数据交换


#账号密码配置于 user.xml

http接口
curl "http://127.0.0.1:8123?query=select%201"


#使用mysql客户端连接
mysql -udefault -h 172.17.0.3 -P 9004 


#原生客户端连接（类mysql语法）
clickhouse-client --config-file=/etc/clickhouse-server/config.xml



#不支持 delete update


内部表所在的库
system



副本(replica) 是指两个相同数据的表或表一部分，作用是为了数据备份与安全
分片(shard)   是指不同的服务器存储同一张表的不同部分，作用是为了水平切分表，缓解单一服务的压力
<remote_servers>标签配置shard与replica

# 如下则
# node1和node2数据一样 
# node3和node4数据一样 
# node1、node3 数据分片
<shard>
    <replica>
        <host>node1</host>
        <port>9000</port>
    </replica>
    <replica>
        <host>node2</host>
        <port>9000</port>
    </replica>
</shard>
<shard>
    <replica>
        <host>node3</host>
        <port>9000</port>
    </replica>
    <replica>
        <host>node4</host>
        <port>9000</port>
    </replica>
</shard>
         

         
select * from clusters;

# 创建表时通过指定cluster_name实现表副本与分片的设置，因此在启动前服务应该在配置文件设置好remote_servers
create table table_name on cluster cluster_name (...) engine=ReplicatedMergeTree(...)      
# 需要分布式表选择一个replica写入即可，由ReplicatedMergeTree完成数据同步，而不需要每个replica都要写入，需要设置 <internal_replication>true<internal_replication>
# 如果 engine=MergeTree 则不行

# 创建分布式表
create table table_name_all as table_name engine=Distributed(cluster_name,db_name,table_name,sharding_key);

sharding_key 也可以为 rand()

# 通过table_name能看到分片/副本的原始数据 通过table_name_all实际读写数据

    
    
    
    